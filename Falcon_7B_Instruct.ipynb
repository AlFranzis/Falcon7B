{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlFranzis/Falcon7B/blob/main/Falcon_7B_Instruct.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Colab-Notebook für den [c't-Artikel](https://ct.de) aus 19/2023 S. 114 und [heise+](https://www.heise.de/hintergrund/Sprach-KI-Wie-Sie-Falcon-7B-mit-Google-Colab-ausprobieren-koennen-9228240.html)."
      ],
      "metadata": {
        "id": "HXU5lKvHEFsB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FF0QHrBECWw"
      },
      "outputs": [],
      "source": [
        "!pip install -U transformers\n",
        "!pip install -U einops\n",
        "!pip install -U git+https://github.com/huggingface/accelerate.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Falcon-7B-Instruct von Hugging Face herunterladen und installieren."
      ],
      "metadata": {
        "id": "U-OkvB1AFRFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import transformers\n",
        "import torch\n",
        "\n",
        "model = \"tiiuae/falcon-7b-instruct\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model)\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    trust_remote_code=True,\n",
        "    device_map=\"auto\",\n",
        ")"
      ],
      "metadata": {
        "id": "74JFCrF0FX2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt an die KI über die pipeline senden und die Antwort verarbeiten. \\\n",
        "Nach dem ersten gesamten Durchlauf müssen Sie für neue Prompts nur noch den Playbutton links neben den Codekasten betätigen, um der KI den neuen Prompt zu übermitteln."
      ],
      "metadata": {
        "id": "wNE4BgUWFeEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Do you know HL7 FHIR?\"\n",
        "sequences = pipeline(\n",
        "    prompt,\n",
        "    max_length=200,\n",
        "    do_sample=True,\n",
        "    top_k=10,\n",
        "    num_return_sequences=1,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        ")\n",
        "for seq in sequences:\n",
        "    print(f\"Result: {seq['generated_text']}\")"
      ],
      "metadata": {
        "id": "2pTzmJAFGN00"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}